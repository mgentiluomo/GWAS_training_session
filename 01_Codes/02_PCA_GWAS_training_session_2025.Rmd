---
title: "GWAS training session"
output: html_notebook
authors:
  - name: "Dr. Manuel Gentiluomo"
    affiliation: "University of Pisa"
    url: "https://github.com/mgentiluomo"
    email: "manuel.gentiluomo@unipi.it"
  - name: "Riccardo Farinella"
    affiliation: "University of Pisa"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
---



üß¨ Array Data Preparation: From Raw Genotypes to PLINK FormatBefore commencing any GWAS analysis, it's crucial to understand the origin and structure of the genetic data. This data is typically generated by Genotyping Array technologies (such as Illumina or Affymetrix) which detect genetic variants (the genotype) at thousands or millions of known genomic locations (SNPs).

1. üî† How Array Data (Raw Data) is Generated and Composed
A Genotyping Array is a chip that allows us to simultaneously test many Single Nucleotide Polymorphisms (SNPs).
Generation:
DNA from each individual is hybridised to the chip. The array software (e.g., Illumina's GenomeStudio) reads the signal intensity for the two possible alleles (genetic variants, e.g., A vs. G) at each SNP position.
Composition (Raw Genotype Data):
The result isn't immediately in a PLINK-readable format, but is usually a text file containing: 
- Sample Identifier (Sample ID): The individual being analysed.
- SNP Identifier (SNP ID): The tested genetic location.
- Raw Allelic Genotype: The raw genotype reading for that sample and SNP (e.g., AA, AG, GG, or sometimes in A/T, C/G format, etc.).

https://unipiit-my.sharepoint.com/:f:/g/personal/a035503_unipi_it/EvcItWiDOsRAn38jZlsxlZQBfta4Ifl0Y-W88ngGI7CZZQ?e=73j4pV

2. ‚û°Ô∏è Converting to PLINK FormatPLINK software is the de facto standard tool for GWAS analysis, but it requires data to be in a specific format to operate efficiently. This format is known as the PLINK Binary format (.bed, .bim, .fam). 
Extension | File | NameContent
.fam | Pedigree/Phenotype | Information about individuals (Family ID, Individual ID, Sex, Phenotype Status).
.bim | Genetic Map | Information about the SNPs (Chromosome, Physical Position, Alleles).
.bed | Genotype Data| The actual binary genotypes (AA, AG, GG, etc.) compressed into an efficient format for PLINK reading.

The Step from Array Matrix to PLINK:
1) Cleaning and Re-formatting: The raw output file must first be cleaned and converted into an intermediate text format (sometimes called PLINK Long Format or TPED/TFAM format).
2) PLINK Conversion: The command plink --make-bed is then used on the text format to generate the three essential binary files (.bed, .bim, and .fam).

Our entire training session will commence using files already in the PLINK Binary format.


############################################################ #############################
üõ†Ô∏è Environment Setup and Prerequisites
Before starting the analysis pipeline, please follow these steps to organize your files and ensure you have all the necessary software installed. This organization is critical for the reproducibility of the entire course.

1. Folder Setup
Create the Main Project Folder: On your Desktop, create a new folder named Class_folder.

Save the Notebook: Place this R Markdown Notebook (.Rmd file) directly inside the Class_folder/.

Data Placement: All subsequent data files (PLINK data, phenotype files, etc.) that you download will be placed inside the Class_folder/ as well, usually in the 01_Database/ directory, which will be created automatically.

Your final folder structure should look like this initially:

Desktop/
‚îî‚îÄ‚îÄ Class_folder/
    ‚îú‚îÄ‚îÄ Your_GWAS_Notebook.Rmd (This file)
    ‚îî‚îÄ‚îÄ (Other files will be created or placed here)

2. Required Software
You must have the following core software installed and accessible on your system:

R and RStudio: You should have the latest versions of R and the RStudio IDE installed. RStudio is required to run the R Markdown Notebook effectively.

PLINK: The entire Quality Control (QC) and Association Analysis pipeline relies heavily on the command-line genetic analysis tool, PLINK.

Action: You need to download the appropriate executable file for your operating system (Windows, macOS, or Linux) from the official PLINK website.

Accessibility: Ensure that the PLINK executable is either saved directly inside your Class_folder/ or, ideally, added to your system's PATH so that the system("plink ...") commands in this notebook can execute it from anywhere.

(PLINK installation and usage details will be covered in the next sections or in your accompanying slides.)

############################################################ #############################


üíª R Code Explanation: Package Installation and Setup
This specific code chunk is crucial for ensuring a smooth start to your GWAS training session. Its primary goal is to check, install, and load all the necessary R packages required for the downstream data analysis, manipulation, and visualisation.

```{r #1.a - Installation of needed packages}
# Installation of packages
packages <- c("base", "readxl", "readr", "dplyr", "ggplot2", "car", "utils", "qqman", "GGally", "ggfortify")
for (pkg in packages) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg)
    library(pkg, character.only = TRUE)
  }
}
rm(packages,pkg)
```

A fundamental step in reproducible analysis is ensuring your script knows where to find the input data (data/ folder) and where to save the results (results/ folder).

When working with R Markdown, the working directory often defaults to the location of the .Rmd file itself. The following code automatically detects the path of the currently running notebook, regardless of whether you are executing it interactively in RStudio or rendering it to HTML/PDF.


Move this notebook inside the working folder
in our case is Class_folder/

```{r #1.b1 - Set of working directories}
#This chunk uses specialized functions to determine the exact folder where this notebook file resides.

# Check if the script is running interactively or being rendered
if (interactive()) {
  # Get the directory of the current R Markdown file in RStudio
  library(rstudioapi)
  notebook_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
} else {
  # Get the directory of the file during rendering
  notebook_dir <- dirname(normalizePath(knitr::current_input()))
}



# Set the working directory to the notebook's directory
setwd(notebook_dir)

# Define the main directory as the current working directory
main <- paste0(getwd(), "/")

# Print the directory for verification
print(notebook_dir)

```

This code chunk sets the local working directory and then defines a structured directory hierarchy to organise all intermediate files, data, and results generated throughout the multi-stage GWAS pipeline. This organisation is crucial for reproducibility and easy navigation.

Code Explanation: Defining Paths and Creating Folders
I. Establishing the Main Root
II. Defining the Pipeline Subdirectories
III. Creating the Folders


```{r #2 Plink}
# PLINK command setup (PLINK 2 and PLINK 1.9)

# 1. Retrieve system information
os_name <- Sys.info()[["sysname"]]

# 2. Define PLINK2 and PLINK 1.9 commands based on the operating system
if (os_name == "Windows") {
  # On Windows, executables normally end with .exe
  plink_command     <- "plink2.exe"  # PLINK 2 (already downloaded in the QC lesson)
  plink_command_old <- "plink.exe"   # PLINK 1.9 (will be added by a later chunk)
  
} else if (os_name %in% c("Darwin", "Linux")) {
  # 'Darwin' is the macOS kernel
  # On macOS/Linux we usually run executables from the current folder with "./"
  plink_command     <- "./plink2"    # PLINK 2 (already present from the QC lesson)
  plink_command_old <- "./plink"     # PLINK 1.9 (will be added by a later chunk)
  
} else {
  stop("Unsupported or unidentified operating system.")
}

# 3. Print the result for verification
cat("Detected operating system:        ", os_name, "\n")
cat("PLINK 2 command to be used:       ", plink_command, "\n")
cat("PLINK 1.9 (old) command to be used:", plink_command_old, "\n")

# --- Example usage (optional checks) ---

cat("\n--- Testing PLINK 2 (if available) ---\n")
system(paste(plink_command, "--version"))

cat("\n--- Testing PLINK 1.9 (if available) ---\n")
system(paste(plink_command_old, "--version"))

print("End of chunk 2")
```

```{r download_and_prepare_plink1.9}
# Download and prepare PLINK 1.9 (old PLINK)
# This chunk does NOT modify or overwrite plink2.
# It simply adds the plink 1.9 executable alongside it.

# Use the existing notebook directory if defined; otherwise fall back to the current working directory
if (!exists("notebook_dir")) {
  notebook_dir <- getwd()
}

# Detect the operating system (reuse os_name if it already exists)
if (!exists("os_name")) {
  os_name <- Sys.info()[["sysname"]]
}

# Define the PLINK 1.9 download URLs (update these if a newer build is released)
plink_url_mac     <- "https://s3.amazonaws.com/plink1-assets/plink_mac_20250819.zip"
plink_url_windows <- "https://s3.amazonaws.com/plink1-assets/plink_win64_20250819.zip"

# Choose the correct URL based on the operating system
if (os_name == "Windows") {
  plink_url <- plink_url_windows
} else if (os_name == "Darwin") {
  plink_url <- plink_url_mac
} else {
  stop("This PLINK 1.9 download script currently supports only Windows and macOS.")
}

# Derive the ZIP file name from the URL
file_name <- basename(plink_url)

# Define the destination path for the ZIP file
dest_file <- file.path(notebook_dir, file_name)

# Download the ZIP file
message("‚¨áÔ∏è Downloading PLINK 1.9 from: ", plink_url)
download.file(url = plink_url, destfile = dest_file, mode = "wb")

# Confirm that the ZIP file exists
if (!file.exists(dest_file)) {
  stop("Download failed: ZIP file not found at ", dest_file)
}

# Create a folder to extract the ZIP contents (named after the ZIP file, without .zip)
extract_dir <- file.path(
  notebook_dir,
  tools::file_path_sans_ext(basename(dest_file))
)

if (!dir.exists(extract_dir)) dir.create(extract_dir)

# Unzip the contents into extract_dir
unzip(zipfile = dest_file, exdir = extract_dir)
message("Extracted: ", basename(dest_file), " ‚Üí ", extract_dir)

# Find any file inside the extracted folder that contains "plink" in its name
# (this will typically include "plink" / "plink.exe", but NOT your existing plink2)
plink_files <- list.files(
  path = extract_dir,
  pattern = "plink",
  full.names = TRUE,
  recursive = TRUE
)

# Copy each found PLINK 1.9 file back into the main notebook directory
for (pf in plink_files) {
  file.copy(from = pf, to = notebook_dir, overwrite = TRUE)
  message("Copied: ", basename(pf), " ‚Üí ", notebook_dir)
}

# On macOS/Linux, ensure the plink 1.9 binary is executable
if (os_name != "Windows") {
  plink_old_path <- file.path(notebook_dir, "plink")
  if (file.exists(plink_old_path)) {
    Sys.chmod(plink_old_path, mode = "0755")
    message("Set executable permissions on: ", plink_old_path)
  }
}

# List all PLINK-related files now present in the main notebook directory
message("PLINK-related files in the notebook directory:")
print(list.files(notebook_dir, pattern = "plink", full.names = TRUE))

rm(plink_url,plink_url_mac,plink_url_windows)
```

```{r --pca}
# SECTION 6: Cryptic relatedness check

# Step 1: Prune SNPs for PCA analysis.
system(paste(plink_command, " --bfile 02_QC/QC9_hwe --indep-pairwise 50 5 0.2 --out 03_PCA/Pruned_list_to_PCA"))


# STEP 2: Extraction of independent SNPs
system(paste(plink_command," --bfile 02_QC/QC9_hwe --extract 03_PCA/Pruned_list_to_PCA.prune.in --make-bed --out 03_PCA/DB_to_PCA"))

# STEP 8: PCA calculation
system(paste(plink_command," --bfile 03_PCA/DB_to_PCA --pca --out 03_PCA/PCA"))
```

```{r PLOTs libraries}
# Make sure the required packages are loaded
library(ggplot2)
library(dplyr)
library(readxl)
library(ggfortify)
```

```{r PLOTs - scree_plot Eigenvalue}
# 1. Create the timestamp (e.g., "20251126_122805")
# %Y: Year with 4 digits, %m: Month, %d: Day
# %H: Hour (24h), %M: Minutes, %S: Seconds
timestamp <- format(Sys.time(), "%m%d_%H%M%S")


### 1. getting Data PCA and Scree Plot

# Load PCA eigenvalues
PCA_val <- read.table("03_PCA/PCA.eigenval", quote = "", comment.char = "")
names(PCA_val) <- "Eigenvalue"
```


```{r PLOTs - scree_plot Eigenvalue explainers}
PCA_val$PC = paste("PC",1:length(PCA_val$Eigenvalue), sep="")
PCA_val$ExplainedVariance <- PCA_val$Eigenvalue/sum(PCA_val$Eigenvalue)
PCA_val$CumulativeVariance <- cumsum(PCA_val$ExplainedVariance)
```


```{r PLOTs - scree_plot}
timestamp <- format(Sys.time(), "%m%d_%H%M%S")
# Draw the scree plot
PCA_val$PC <- factor(PCA_val$PC, levels = paste("PC", 1:length(PCA_val$Eigenvalue), sep = ""))
scree_p = ggplot(PCA_val, aes(x = PC)) +
    geom_bar(aes(y = ExplainedVariance * 100, fill = "Explained Variance"), stat = "identity", alpha = 0.7) +
    geom_line(aes(y = CumulativeVariance * 100, color = "Cumulative Variance"), group = 1, size = 1) +
    geom_point(aes(y = CumulativeVariance * 100, color = "Cumulative Variance"), size = 2) +
    scale_y_continuous(
        name = "Explained Variance (%)",
        labels = scales::label_percent(scale = 1), 
        sec.axis = sec_axis(
            trans = ~ ., 
            name = "Cumulative Variance (%)",
            labels = scales::label_percent(scale = 1)
        )
    ) +
    scale_fill_manual(values = c("skyblue")) +
    scale_color_manual(values = c("Cumulative Variance" = "red")) +
    labs(
        title = "Variance Explained and Cumulative Variance",
        x = "Principal Components",
        fill = "", color = ""
    ) + theme_bw() + theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

# Save the scree plot
ggsave(filename = paste("03_PCA/","scree_plot_",timestamp,".jpeg", sep = ""), plot = scree_p, width = 8, height = 6, dpi = 600)
```

```{r PCA eigenvectors}
# Load PCA eigenvectors
PCA <- read.delim("03_PCA/PCA.eigenvec", quote = "",)
num_pca_columns <- ncol(PCA) - 2
colnames(PCA) <- c("FID", "IID", paste0("PC", 1:num_pca_columns))
```

```{r COVAR}
# Import study population covariates, such as sex, phenotype (likely already updated in the .fam file), age, BMI, etc.
COV <- read.delim("02_Database/general_covar.txt", quote = "")
```


```{r prepare df for plotting PCA by groups - FAM}
library(dplyr)
library(stringr) # Required for str_detect

# Loading and preparing phenotype data (pheno)
FAM <- read.table("02_QC/QC9_hwe.fam", quote = "", comment.char = "")
names(FAM) <- c("FID", "IID", "f", "m", "sex", "phenotype")
```


```{r prepare df for plotting PCA by groups - ID_label}
# Merge country data (ID_label) and phenotype data (FAM)
ID_label <- merge(COV, FAM %>% select(FID, IID, phenotype), 
                  by = c("FID", "IID"), all.y = TRUE)

ID_label <- dplyr::select(ID_label, c("FID", "IID", "Group", "pheno"))

# Merge PCA results with label data
dfPCA <- merge(PCA, ID_label, by = c("FID", "IID"), all.x = TRUE)

# Ensure that 'Group' and 'pheno' are factors for plotting
dfPCA$pheno <- as.factor(dfPCA$pheno) # Use pheno as the status/colour column
dfPCA$Group <- as.factor(dfPCA$Group) # Use pheno as the status/colour column
```


```{r PLOTs}
timestamp <- format(Sys.time(), "%m%d_%H%M%S")

### 3. PCA Visualisation (Colour by Status, Shape by Centre/Group)

# Compute explained variance (for axis labels)
explained_var <- as.vector(round(slice(dplyr::select(PCA_val, c("ExplainedVariance")), c(1,2))*100, digits = 2)$ExplainedVariance)

# Run PCA to obtain the 'pca_res' object required for autoplot
pca_res <- prcomp(dplyr::select(dfPCA, starts_with("PC")), scale. = FALSE)

# Create the final plot
plot_final <- autoplot(pca_res, data = dfPCA, 
                       colour = "pheno",  # <--- COLOUR based on Status (Case/Control)
                       shape = "Group",   # <--- SHAPE based on Group
                       size = 3) + 
    theme_bw() + 
    
    # Add axis labels
    xlab(paste("PC1 (", explained_var[1], "%)", sep="")) + 
    ylab(paste("PC2 (", explained_var[2], "%)", sep="")) + 
    
    # Plot title
    ggtitle("PCA: Group (Shape) vs Case/Control Status (Colour)") +
    
    # Customise COLOURS (optional, assign specific colours to Case/Control)
    scale_color_manual(name = "Status",
                       values = c("Case" = "red",        # Example: Cases in Red
                                  "Control" = "blue")) +  # Example: Controls in Blue
                                  
    # Customise legend appearance
    theme(legend.position = "right",
          plot.title = element_text(size = 14, face = "bold"),
          legend.title = element_text(size = 10, face = "bold"))

# Save the plot
ggsave(filename = paste("03_PCA/","pca_status_Group_swapped_",timestamp,".jpeg", sep=""), 
       plot = plot_final, width = 10, height = 7, dpi = 600)
```

```{r PLOTs by case control}
timestamp <- format(Sys.time(), "%m%d_%H%M%S")

### 3. PCA Visualisation (Colour by Status, Shape by Centre/Group)

# Compute explained variance (for axis labels)
explained_var <- as.vector(round(slice(dplyr::select(PCA_val, c("ExplainedVariance")), c(1,2))*100, digits = 2)$ExplainedVariance)

# Run PCA to obtain the 'pca_res' object required for autoplot
pca_res <- prcomp(dplyr::select(dfPCA, starts_with("PC")), scale. = FALSE)

# Create the final plot
plot_final <- autoplot(pca_res, data = dfPCA, 
                       colour = "pheno",  # <--- COLOUR based on Status (Case/Control)
                       shape = "Group",   # <--- SHAPE based on Group
                       size = 3) + 
    theme_bw() + 
    
    # Add axis labels
    xlab(paste("PC1 (", explained_var[1], "%)", sep="")) + 
    ylab(paste("PC2 (", explained_var[2], "%)", sep="")) + 
    
    # Plot title
    ggtitle("PCA: Group (Shape) vs Case/Control Status (Colour)") +
    
    # Customise COLOURS (optional, assign specific colours to Case/Control)
    scale_color_manual(name = "Status",
                       values = c("Case" = "red",        # Example: Cases in Red
                                  "Control" = "blue")) +  # Example: Controls in Blue
                                  
    # Customise legend appearance
    theme(legend.position = "right",
          plot.title = element_text(size = 14, face = "bold"),
          legend.title = element_text(size = 10, face = "bold"))

# Save the plot
ggsave(filename = paste("03_PCA/","pca_status_Group_swapped_",timestamp,".jpeg", sep=""), 
       plot = plot_final, width = 10, height = 7, dpi = 600)
```


```{r PLOTs}
plot_final <- autoplot(pca_res, data = dfPCA, 
                       colour = "Group",   # <--- COLOUR by PCA Group
                       shape = "pheno",    # <--- SHAPE by Case/Control
                       size = 3) + 
    theme_bw() + 
    
    # Axis labels
    xlab(paste("PC1 (", explained_var[1], "%)", sep="")) + 
    ylab(paste("PC2 (", explained_var[2], "%)", sep="")) + 
    
    # Title
    ggtitle("PCA: Group (Colour) vs Case/Control Status (Shape)") +
    
    # Custom colours for the 4 PCA groups
    scale_color_manual(name = "Group",
                       values = c("A" = "#E41A1C",   # red
                                  "B" = "#377EB8",   # blue
                                  "C" = "#4DAF4A",   # green
                                  "X" = "#984EA3")) + # purple
                                  
    # Legend and theme
    theme(legend.position = "right",
          plot.title = element_text(size = 14, face = "bold"),
          legend.title = element_text(size = 10, face = "bold"))

# Save the plot
ggsave(filename = paste("03_PCA/","pca_Group_swapped_",timestamp,".jpeg", sep=""), 
       plot = plot_final, width = 10, height = 7, dpi = 600)
```




```{r}
#Set threshold

PC1_thr_min = 0.01
PC1_thr_max = 1

PC2_thr_min = -0.012
PC2_thr_max = 0.012

Selection <- subset(dfPCA,
                    PC1 >= PC1_thr_min &
                    PC1 <= PC1_thr_max &
                    PC2 >= PC2_thr_min &
                    PC2 <= PC2_thr_max)

Selected_IDs <- Selection[, c("FID", "IID")]

write.table(Selected_IDs, "03_PCA/Group_selection.txt", sep = "\t", row.names = FALSE, quote = FALSE)




```

```{r 1000Genome}
# Define the target directory
DB_dir <- file.path(main, "02_Database", "DB_1K_genome")
dir.create(DB_dir, recursive = TRUE, showWarnings = FALSE)

# Define URLs and destination file names
files_to_download <- list(
  bed_1KG = list(
    url  = "https://unipiit-my.sharepoint.com/:u:/g/personal/a035503_unipi_it/IQCMZbnTFipoRYVs_2tIdGk0ARoMtzCjqQ7mh-NY3QT5EG0?e=jYeGS4",
    dest = "DB_1000G.bed"
  ),
  fam_1KG = list(
    url  = "https://raw.githubusercontent.com/mgentiluomo/GWAS_training_session/ba69c0ef61926cc7d1d8a06761aa35ad70f94777/02_Database/DB_1K_genome/DB_1000G.fam",
    dest = "DB_1000G.fam"
  ),
  bim_1KG = list(
    url  = "https://raw.githubusercontent.com/mgentiluomo/GWAS_training_session/ba69c0ef61926cc7d1d8a06761aa35ad70f94777/02_Database/DB_1K_genome/DB_1000G.bim",
    dest = "DB_1000G.bim"
  ),
  info_1KG = list(
    url  = "https://raw.githubusercontent.com/mgentiluomo/GWAS_training_session/ba69c0ef61926cc7d1d8a06761aa35ad70f94777/02_Database/DB_1K_genome/1000G_individuals.xlsx",
    dest = "1000G_individuals.xlsx"
  )
)

# Loop to download each file
for (name in names(files_to_download)) {
  url       <- files_to_download[[name]]$url
  dest_name <- files_to_download[[name]]$dest
  dest_file <- file.path(DB_dir, dest_name)
  
  if (!file.exists(dest_file)) {
    message("‚¨áÔ∏è Downloading ", name, " file (", dest_name, ") ...")
    download.file(url, destfile = dest_file, mode = "wb")
  } else {
    message("‚úÖ File already exists: ", dest_name)
  }
}

#Import 1000Genome data info
oneTGenome <- read_excel("02_Database/DB_1K_genome/1000G_individuals.xlsx", col_names = FALSE)
names(oneTGenome) <- c("FID","IID","Population")
```


```{r 1000Genome}
BIM_DB <- read.table("02_QC/QC9_hwe.bim", header = F)
BIM_1KG <- read.table("02_Database/DB_1K_genome/DB_1000G.bim", header = F)
```


```{r 1000Genome}
system(paste(
  plink_command_old,
  "--bfile 02_QC/QC9_hwe",
  "--bmerge 02_Database/DB_1K_genome/DB_1000G.bed 02_Database/DB_1K_genome/DB_1000G.bim 02_Database/DB_1K_genome/DB_1000G.fam",
  "--out 03_PCA/DB_merged_1KG"
))

system(paste(
  plink_command_old,
  "--bfile 02_Database/DB_1K_genome/DB_1000G",
  "--flip 03_PCA/DB_merged_1KG.missnp",
  "--make-bed",
  "--out 03_PCA/DB_flippedd_1KG"
))


system(paste(
  plink_command_old,
  "--bfile 02_QC/QC9_hwe",
  "--bmerge 03_PCA/DB_flippedd_1KG.bed 03_PCA/DB_flippedd_1KG.bim 03_PCA/DB_flippedd_1KG.fam",
  "--out 03_PCA/DB_merged_1KGv2"
))


system(paste(
  plink_command_old,
  "--bfile 03_PCA/DB_flippedd_1KG",
  "--exclude 03_PCA/DB_merged_1KGv2.missnp",
  "--make-bed",
  "--out 03_PCA/DB_flippedd_1KGv2"
))


system(paste(
  plink_command_old,
  "--bfile 02_QC/QC9_hwe",
  "--bmerge 03_PCA/DB_flippedd_1KGv2.bed 03_PCA/DB_flippedd_1KGv2.bim 03_PCA/DB_flippedd_1KGv2.fam",
  "--out 03_PCA/DB_merged_1KG_final"
))
```


```{r 1000Genome merged QC}
#system(paste(
  plink_command_old,
  "--bfile 03_PCA/DB_merged_1KG_final",
  "--geno 0.15 --mind 0.15",
  "--make-bed",
  "--out 03_PCA/DB_merged_1KG_clean"
))


```

```{r --pca 1KG}
# SECTION 6: Cryptic relatedness check

# Step 1: Prune SNPs for PCA analysis.
system(paste(plink_command, " --bfile 03_PCA/DB_merged_1KG_clean --indep-pairwise 50 5 0.2 --out 03_PCA/Pruned_list_to_PCA1kG"))


# STEP 2: Extraction of independent SNPs
system(paste(plink_command," --bfile 03_PCA/DB_merged_1KG_clean --extract 03_PCA/Pruned_list_to_PCA1kG.prune.in --make-bed --out 03_PCA/DB_to_PCA1kG"))

# STEP 8: PCA calculation
system(paste(plink_command," --bfile 03_PCA/DB_to_PCA1kG --pca --out 03_PCA/PCA1kG"))
```




```{r PCA eigenvectors 1KG}
#Load PCA eigenvectors
PCA <- read.delim("03_PCA/PCA1kG.eigenvec", quote = "",)
num_pca_columns <- ncol(PCA) - 2
colnames(PCA) <- c("FID", "IID", paste0("PC", 1:num_pca_columns))
```

```{r}
Database <- merge(PCA,oneTGenome,all.x = T, by = c("FID","IID"))

table(Database$Population)


```





